{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 692. Top K Frequent Words\n",
    "Given an array of strings `words` and an integer `k`, return the `k` most frequent strings.\n",
    "\n",
    "Return the answer sorted by the frequency from highest to lowest. Sort the words with the same frequency by their\n",
    "lexicographical order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Timing** \\\n",
    "**Start: 13:43** \\\n",
    "**End: 14:05**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planning\n",
    "I am thinking of using a hash map to count the frequency of the words.\n",
    "\n",
    "I will create an integer-based default dict, and then iterate/pop each index of the\n",
    "list and add a value to the default dict.\n",
    "\n",
    "At the end, I will get the key and value pairs of the dict. \n",
    "\n",
    "At this point, I can either argsort the values or I can pop the `k` max keys and add\n",
    "them to the return list. I will test to see which one is simpler.\n",
    "\n",
    "I also need to consider the lexicographical order aspect of this. Maybe I can pull all of the \n",
    "words that have the current max value, and then add the lowest lexicographical word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'is', 'sunny', 'day']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def top_k_frequent(words, k):\n",
    "    from collections import defaultdict\n",
    "\n",
    "    # get the word counts\n",
    "    word_counts = defaultdict(int)\n",
    "    while len(words):\n",
    "        word_counts[words.pop()] += 1\n",
    "\n",
    "    # get the most frequent words\n",
    "    frequent_words = []\n",
    "    keys, values = list(word_counts.keys()), list(word_counts.values())\n",
    "\n",
    "    for i in range(k):\n",
    "        # get the current highest count\n",
    "        current_max = max(values)\n",
    "\n",
    "        # get the current index of the max word\n",
    "        max_count = values.count(current_max)\n",
    "        if max_count == 1:  # easy identification if there is only one count of word\n",
    "            current_max_index = values.index(current_max)\n",
    "        else:  # otherwise...\n",
    "            # get all of the words with the max count and their absolute indices\n",
    "            indices, candidate_words = list(\n",
    "                zip(\n",
    "                    *[\n",
    "                        [i, word]\n",
    "                        for i, word in enumerate(keys)\n",
    "                        if values[i] == current_max\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # find the relative position of the lexicographically lowest word\n",
    "            relative_current_max_index = candidate_words.index(min(candidate_words))\n",
    "            \n",
    "            # convert to the max index\n",
    "            current_max_index = indices[relative_current_max_index]\n",
    "            \n",
    "        frequent_words.append(keys.pop(current_max_index))\n",
    "        values.pop(current_max_index)\n",
    "\n",
    "    return frequent_words\n",
    "\n",
    "\n",
    "words = [\"the\", \"day\", \"is\", \"sunny\", \"the\", \"the\", \"the\", \"sunny\", \"is\", \"is\"]\n",
    "k = 4\n",
    "top_k_frequent(words, k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Afterthoughts\n",
    "**Stats:**\n",
    "Runtime\n",
    "79 ms\n",
    "Beats\n",
    "61.88%\n",
    "Memory\n",
    "13.7 MB\n",
    "Beats\n",
    "20.32%\n",
    "\n",
    "I'm quite happy with this solution. Managing the relative indices and sorting a sublist\n",
    "of to find the lexicographically 'smallest' word reminds me of my management of relative\n",
    "indices when I was working with vasculature graph processing.\n",
    "\n",
    "I'm going to check to see what other solutions were implemented to learn a more elegant\n",
    "approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like an approach that others have taken is to create an object that stores\n",
    "the word and value of each word in words.\n",
    "\n",
    "They then create a list of these objects, and sort the list with custom `compare` functions.\n",
    "\n",
    "Then they just return the `k` largest words in the list. I like this approach but don't feel\n",
    "it necessary to worry about implementing it here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit ('learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "083c3123b4ad7f25f53c003e80272d3d1894a33e093a79f10823ee80b0414ebd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
