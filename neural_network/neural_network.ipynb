{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "**Outline**\n",
    "1. What are Neural Networks?\n",
    "2. Getting Started\n",
    "3. Constructing the Network\n",
    "    1. Initialization\n",
    "    2. Forward Pass\n",
    "    3. Backward Pass\n",
    "    4. Loss Function\n",
    "    5. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Architecture:\n",
    "1. Forward Pass\n",
    "2. Backward Pass\n",
    "\n",
    "Forward  Pass:\n",
    "1. Dot Product\n",
    "3. Bias\n",
    "2. Activation Function\n",
    "\n",
    "Backward Pass:\n",
    "1. Loss Function (cross entropy)\n",
    "2. Derivaties of each function\n",
    "    1. Hidden layer derivatives, including ReLU\n",
    "    2. Softmax derivative\n",
    "    3. Cross Entropy derivative\n",
    "\n",
    "Optimizer:\n",
    "1. Adam Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def he_initialization(layer_size: int, previous_layer_size: int):\n",
    "    \"\"\"Generate a layer with He initialization.\n",
    "    \n",
    "    Parameters:\n",
    "        layer_size: int\n",
    "        \n",
    "        previous_layer_size: int\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray\n",
    "    \"\"\"\n",
    "    W = np.random.randn(layer_size, previous_layer_size)\n",
    "    standard_dev = np.sqrt(2 / previous_layer_size)\n",
    "    W *= standard_dev\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\"Returns a neural network with the defined layer counts. \n",
    "    \n",
    "    Uses ReLU activations for the hidden a softmax activation function for the output\n",
    "    layer.\n",
    "    \n",
    "    Initializes the layer weights with He initialization.\n",
    "    \n",
    "    Parameters:\n",
    "        input_layer_size: int\n",
    "        \n",
    "        hidden_layer_sizes: list\n",
    "            A (n,) shaped list indicating the sizes of the layers.\n",
    "            \n",
    "        output_layer_size: int\n",
    "    \n",
    "    Attributes: \n",
    "        layers: list \n",
    "            A list of numpy arrays.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 input_layer_size: int,\n",
    "                 hidden_layer_sizes: list,\n",
    "                 output_layer_size: int):        \n",
    "        self.layers = {}\n",
    "        self.layer_count = len(hidden_layer_sizes) + 1\n",
    "        \n",
    "        layer_sizes = [input_layer_size, *hidden_layer_sizes, output_layer_size]\n",
    "\n",
    "        for i, size in enumerate(layer_sizes[1:]):\n",
    "            n = layer_sizes[i]  # units in previous layer\n",
    "            std = np.sqrt(2.0 / n)\n",
    "            layer_w = np.random.randn(size) * std\n",
    "            \n",
    "            self.layers[\"W\"+str(i+1)] = layer_w\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work on the __init__ first. \n",
    "image_dimensions = (28,28)\n",
    "class_count = 10\n",
    "network = NeuralNetwork(np.prod(image_dimensions), [20, 10], class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([ 5.80774344e-02, -8.65143947e-02, -1.84246494e-02, -1.20113255e-02,\n",
       "         3.21817108e-02,  3.75999021e-02,  3.07950731e-02,  1.83280040e-02,\n",
       "        -1.12254117e-02, -2.92047626e-02, -2.42031527e-02, -1.17832965e-02,\n",
       "        -6.02444857e-02, -6.52979201e-02, -3.06396036e-02, -7.42498825e-03,\n",
       "         1.84641315e-02,  9.82501105e-05, -1.86470269e-02,  2.18508074e-02]),\n",
       " 'W2': array([ 0.23191197, -0.6580372 ,  0.2684691 ,  0.78227738,  0.19311967,\n",
       "         0.15488177,  0.12355032,  0.25647246,  0.09976077, -0.05213133]),\n",
       " 'W3': array([ 0.54887089, -0.5827096 , -0.44616307,  0.33381212, -0.58132617,\n",
       "        -0.13475367, -0.79514653, -0.15067524, -0.43078385, -0.27735475])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit ('learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "083c3123b4ad7f25f53c003e80272d3d1894a33e093a79f10823ee80b0414ebd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
